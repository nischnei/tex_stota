@article{Badino2011,
author = {Badino, Hernan and Huber, Daniel and Kanade, Takeo},
file = {:C$\backslash$:/Users/Nick/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Badino, Huber, Kanade - 2011 - Integrating LIDAR into Stereo for Fast and Improved Disparity Computation.pdf:pdf},
keywords = {-stereo,disparity space reduction,dynamic program-,lidar,ming,path promotion,range images,sensor fusion},
title = {{Integrating LIDAR into Stereo for Fast and Improved Disparity Computation}},
year = {2011}
}
@inproceedings{Badino2011a,
abstract = {The fusion of stereo and laser range finders (LIDARs) has been proposed as a method to compensate for each individual sensor's deficiencies - stereo output is dense, but noisy for large distances, while LIDAR is more accurate, but sparse. However, stereo usually performs poorly on textureless areas and on scenes containing repetitive structures, and the subsequent fusion with LIDAR leads to a degraded estimation of the 3D structure. In this paper, we propose to integrate LIDAR data directly into the stereo algorithm to reduce false positives while increasing the density of the resulting disparity image on textureless regions. We demonstrate with extensive experimental results with real data that the disparity estimation is substantially improved while speeding up the stereo computation by as much as a factor of five.},
author = {Badino, Hernan and Huber, Daniel and Kanade, Takeo},
booktitle = {Proceedings - 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission, 3DIMPVT 2011},
doi = {10.1109/3DIMPVT.2011.58},
isbn = {9780769543697},
keywords = {Disparity space reduction,Diss,Dynamic programming,LIDAR,Path promotion,Range images,Sensor fusion,Stereo},
mendeley-tags = {Diss},
pages = {405--412},
title = {{Integrating LIDAR into stereo for fast and improved disparity computation}},
year = {2011}
}
@article{Baig2011,
author = {Baig, Qadeer and Aycard, Olivier and Vu, Trung Dung and Fraichard, Thierry},
doi = {10.1109/IVS.2011.5940576},
file = {:C$\backslash$:/Users/Nick/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Baig et al. - 2011 - Fusion between laser and stereo vision data for moving objects tracking in intersection like scenario.pdf:pdf},
isbn = {978-1-4577-0890-9},
journal = {2011 IEEE Intelligent Vehicles Symposium (IV)},
keywords = {DISS},
mendeley-tags = {DISS},
month = jun,
pages = {362--367},
publisher = {Ieee},
title = {{Fusion between laser and stereo vision data for moving objects tracking in intersection like scenario}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5940576},
year = {2011}
}
@article{Broggi2006,
author = {Broggi, Alberto and Cattani, Stefano and Porta, Pier Paolo and Zani, Paolo and Dipartimento, Vislab},
file = {:C$\backslash$:/Users/Nick/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Broggi et al. - 2006 - A Laserscanner-Vision Fusion System Implemented on the TerraMax Autonomous Vehicle.pdf:pdf},
isbn = {142440259X},
pages = {111--116},
title = {{A Laserscanner-Vision Fusion System Implemented on the TerraMax Autonomous Vehicle}},
year = {2006}
}
@article{Conner,
author = {Conner, David C and Kedrowski, Philip R and Reinholtz, Charles F and Engineering, Mechanical and Tech, Virginia},
file = {:C$\backslash$:/Users/Nick/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Conner et al. - Unknown - Multiple camera , laser rangefinder , and encoder data fusion for navigation of a differentially steered 3-whe.pdf:pdf},
keywords = {autonomous vehicles,mobile robots,sensor fusion,vector field histogram},
title = {{Multiple camera , laser rangefinder , and encoder data fusion for navigation of a differentially steered 3-wheeled autonomous vehicle}}
}
@phdthesis{Elmenreich2002,
abstract = {Sensor fusion is the combining of sensory data or data derived from sensory data in order to produce enhanced data in form of an internal represen- tation of the process environment. The achievements of sensor fusion are robustness, extended spatial and temporal coverage, increased confidence, reduced ambiguity and uncertainty, and improved resolution. This thesis examines the application of sensor fusion for real-time ap- plications. The time-triggered approach provides a well suited basis for building real-time systems due to its highly deterministic behavior. The integration of sensor fusion applications in a time-triggered framework sup- ports resource-efficient dependable real-time systems. We present a time- triggered approach for real-time sensor fusion applications that partitions the system into three levels: First, a transducer level contains the sensors and the actuators. Second, a fusion/dissemination level gathers measure- ments, performs sensor fusion and distributes control information to the actuators. Third, a control level contains a control program making control decisions based on environmental information provided by the fusion le- vel. Using this architecture, complex applications can be decomposed into smaller manageable subsystems. Furthermore, this thesis evaluates different approaches for achieving de- pendability. These approaches attack the problem at different levels. At the transducer level, we introduce a filter algorithm that performs successive measurements in order to improve the data quality of a single sensor. A dif- ferent approach improves data by combining data of multiple sensors at the fusion/dissemination level. We propose two sensor fusion algorithms to ac- complish this task, the systematic confidence-weighted averaging algorithm and the application-specific robust certainty grid algorithm. The proposed methods are evaluated and used in a case study featuring an autonomous mobile robot.},
author = {Elmenreich, Wilfried},
file = {:D$\backslash$:/Paper/Unknown/Elmenreich - 2002 - Sensor Fusion in Time-Triggered Systems.pdf:pdf},
number = {9226605},
pages = {157},
title = {{Sensor Fusion in Time-Triggered Systems}},
year = {2002}
}
@inproceedings{Haberjahn2010,
author = {Haberjahn, Mathias},
doi = {973-3-942709-00-2},
file = {:C$\backslash$:/Users/Nick/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Haberjahn - 2010 - Low-Level-Fusion eines Laserscanner- und Stereokamera- Systems in der Fahrzeugumfelderfassung.pdf:pdf},
keywords = {DISS},
mendeley-tags = {DISS},
pages = {187},
title = {{Low-Level-Fusion eines Laserscanner- und Stereokamera- Systems in der Fahrzeugumfelderfassung}},
year = {2010}
}
@phdthesis{Haberjahn2013,
abstract = {With the present thesis a contribution to the increase of the accuracy and reliability of a sensor-supported recognition and tracking of objects in a vehicleâ€™s surroundings should be made. Based on a detection system, consisting of a stereo camera and a laser scanner, novel developed procedures are introduced for the whole processing chain of the sensor data. In addition, a new framework is introduced for the fusion of heterogeneous sensor data. By combining the data fusion results from the different processing levels the object detection can be improved. After a short description of the used sensor setup the developed procedures for the cali- bration and mutual orientation are introduced. As a result, the measuring error for the laser scanner can be reduced by over 10 \%. With the segmentation of the spatial point data existing procedures are extended by the inclusion of measuring accuracy and specificity of the sensor. Furthermore, an approach for the determination of the minimally enclosing object box and the object alignment to support the object tracking is introduced. In the subsequent object tracking a new computation-optimized approach for the asso- ciation of the related object hypotheses is presented. In addition, a model for a dynamic determination and tracking of an object reference point is described which exceeds the clas- sical tracking of the object center in the track accuracy. By the introduced fusion framework it is possible to merge the sensor data at three different processing levels (point, object and track level). A sensor independent approach for the low fusion of point data is demonstrated which delivers the most precise object description in comparison to the other fusion levels and the single sensors. For the higher fusion levels new procedures were developed to discover and clean up the detection and processing mistakes benefiting from the competing sensor information. Finally it is described how the fusion results of the upper and lower levels can be brought together for an ideal object description. The effectiveness of the newly developed methods was checked either by simulation or in real measurement scenarios. The interdisciplinary standard of this thesis lies in the novel concept of a combined multi layer fusion of heterogeneous sensor data for a more reliable and more precise object descrip- tion in the vehicle surrounding field. This concept was implemented in his totality with a technological innovative reference sensor system and tested successfully.},
author = {Haberjahn, Mathias},
file = {:C$\backslash$:/Users/Nick/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Berlin, Haberjahn - Unknown - Multilevel Datenfusion konkurrierender Sensoren in der Fahrzeugumfelderfassung D I S S E R TAT I O N zur E.pdf:pdf},
keywords = {DISS,Multi-Sensor Datenfusion,Multilevel Datenfusion,multi level data fusion,multi sensor data fusion},
mendeley-tags = {DISS},
school = {Humboldt-Universit\"{a}t zu Berlin},
title = {{Multilevel Datenfusion konkurrierender Sensoren in der Fahrzeugumfelderfassung}},
year = {2013}
}
@article{Haberjahn2011,
author = {Haberjahn, Mathias and Junghans, Marek},
doi = {10.1109/ITSC.2011.6083092},
file = {:C$\backslash$:/Users/Nick/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Haberjahn, Junghans - 2011 - Vehicle environment detection by a combined low and mid level fusion of a laser scanner and stereo vision.pdf:pdf},
isbn = {978-1-4577-2197-7},
journal = {2011 14th International IEEE Conference on Intelligent Transportation Systems (ITSC)},
month = oct,
pages = {1634--1639},
publisher = {Ieee},
title = {{Vehicle environment detection by a combined low and mid level fusion of a laser scanner and stereo vision}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6083092},
year = {2011}
}
@article{Hahne2008,
author = {Hahne, Uwe and Alexa, Marc},
file = {:C$\backslash$:/Users/Nick/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hahne, Alexa - 2008 - Combining Time-Of-Flight depth and stereo images without accurate extrinsic calibration.pdf:pdf},
keywords = {2008,and alexa,combining time-of-flight depth and,depth imaging,follows,hahne,m,photonic mixer device,pmd,reference to this paper,sensor fusion,should be made as,stereo,stereo images without accurate,time-of-flight,tof,u},
title = {{Combining Time-Of-Flight depth and stereo images without accurate extrinsic calibration}},
volume = {5},
year = {2008}
}
@article{Jungnickel,
author = {Jungnickel, Ruben},
file = {:C$\backslash$:/Users/Nick/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jungnickel - Unknown - AW1 Ausarbeitung.pdf:pdf},
title = {{Sensorfusion f\"{u}r Automobile}}
}
@article{Klimentjew2010,
author = {Klimentjew, Denis and Hendrich, Norman and Zhang, Jianwei},
doi = {10.1109/MFI.2010.5604459},
file = {:C$\backslash$:/Users/Nick/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Klimentjew, Hendrich, Zhang - 2010 - Multi sensor fusion of camera and 3D laser range finder for object recognition.pdf:pdf},
isbn = {978-1-4244-5424-2},
journal = {2010 IEEE Conference on Multisensor Fusion and Integration},
month = sep,
pages = {236--241},
publisher = {Ieee},
title = {{Multi sensor fusion of camera and 3D laser range finder for object recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5604459},
year = {2010}
}
@article{Labayrade2007,
author = {Labayrade, Rapha\"{e}l and Gruyer, Dominique and Royere, Cyril and Perrollaz, Mathias and Aubert, Didier},
file = {:C$\backslash$:/Users/Nick/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Labayrade et al. - 2007 - Obstacle Detection Based on Fusion Between Stereovision and 2D Laser Scanner.pdf:pdf},
isbn = {3866112831},
number = {February},
title = {{Obstacle Detection Based on Fusion Between Stereovision and 2D Laser Scanner}},
year = {2007}
}
@article{Pfeiffer2011,
author = {Pfeiffer, David and Franke, Uwe},
file = {:C$\backslash$:/Users/Nick/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pfeiffer, Franke - 2011 - Towards a Global Optimal Multi-Layer Stixel Representation of Dense 3D Data.pdf:pdf},
journal = {BMVC},
title = {{Towards a Global Optimal Multi-Layer Stixel Representation of Dense 3D Data.}},
year = {2011}
}
@article{Pfeiffer2010,
author = {Pfeiffer, David and Morales, Sandino and Barth, Alexander and Franke, Uwe},
doi = {10.1109/ITSC.2010.5625017},
file = {:C$\backslash$:/Users/Nick/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pfeiffer et al. - 2010 - Ground truth evaluation of the Stixel representation using laser scanners.pdf:pdf},
isbn = {978-1-4244-7657-2},
journal = {13th International IEEE Conference on Intelligent Transportation Systems},
month = sep,
pages = {1091--1097},
publisher = {Ieee},
title = {{Ground truth evaluation of the Stixel representation using laser scanners}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5625017},
year = {2010}
}
@article{Steger2010,
author = {Steger, Johannes M and Walter, Sven},
file = {:C$\backslash$:/Users/Nick/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Steger, Walter - 2010 - Fusion of 3D Laser Scans and Stereo Images for Disparity Maps of Natural Scenes.pdf:pdf},
title = {{Fusion of 3D Laser Scans and Stereo Images for Disparity Maps of Natural Scenes}},
volume = {14},
year = {2010}
}
@article{Zhu2008,
author = {Zhu, Jiejie and Davis, James},
file = {:C$\backslash$:/Users/Nick/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu, Davis - 2008 - Fusion of Time-of-Flight Depth and Stereo for High Accuracy Depth Maps.pdf:pdf},
isbn = {9781424422432},
title = {{Fusion of Time-of-Flight Depth and Stereo for High Accuracy Depth Maps}},
year = {2008}
}
